{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d7d2bfe-3cf5-4fa4-ab89-948cb05286a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2815d4c2-dee6-408b-a4d5-6380ca4b5261",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAAMLP.pdf          create_data.py      data.ipynb          extracted_data.json\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "532c55b7-a342-47c6-a4cb-87f462a1a7eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('extracted_data.json','r') as w:\n",
    "    data = json.load(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e93dd512-feb0-43db-aede-cbd74bb1f335",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approaching (Almost) Any Machine Learning Problem \n",
      " 40     p = precision(y_true, temp_prediction)     r = recall(y_true, temp_prediction)     precisions.append(p)     recalls.append(r) ═════════════════════════════════════════════════════════════════════════  Now, we can plot these values of precisions and recalls.  ═════════════════════════════════════════════════════════════════════════ plt.figure(figsize=(7, 7)) plt.plot(recalls, precisions) plt.xlabel('Recall', fontsize=15) plt.ylabel('Precision', fontsize=15) ═════════════════════════════════════════════════════════════════════════  Figure 2 shows the precision-recall curve we get this way. \n",
      " Figure 2: precision-recall curve  This precision-recall curve looks very different from what you might have seen on the internet. It’s because we had only 20 samples, and only 3 of them were positive samples. But there’s nothing to worry. It’s the same old precision-recall curve.  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data['Page40'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902261f2-6f9c-4096-a978-8d449d171fad",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Let us clean the data\n",
    "1. remove extra '==' and keep only '=='\n",
    "2. remove extra white spaces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbbc4c95-f936-4510-ad1e-667e8a87eed2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_string(input_string):\n",
    "    \n",
    "    # Remove extra '==' or '...'\n",
    "    input_string = re.sub(r'═{2,}', '==', input_string)\n",
    "    \n",
    "    # Remove extra white spaces\n",
    "    input_string = ' '.join(input_string.split())\n",
    "    \n",
    "    return input_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9ad3f79-b32e-489c-83ad-1b2e488da0e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i,j in data.items():\n",
    "    data[i] = (clean_string(data[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8867c891-d2a8-494c-91ce-4646ae9b6b2a",
   "metadata": {},
   "source": [
    "# Create Embeddings \n",
    "\n",
    "making use of sentence_transformers\n",
    "\n",
    "using `multi-qa-mpnet-base-dot-v1` as it was tuned for semantic search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c397ac5e-f3c0-4980-ac38-6af76a2e87e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('multi-qa-mpnet-base-dot-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "752a3e1f-27cb-460c-9528-cae4f9aea556",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_to_encode = list(data.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf125ef8-f03e-473e-a47d-e295254bbc18",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_to_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "810b038b-00eb-44f8-88e4-4b93da37de2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text_embeddings = model.encode(text_to_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8139c2d4-329a-443b-aa58-b2ff03399855",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 768)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbc5806-0b8f-4055-b97a-aabc4569b7d7",
   "metadata": {},
   "source": [
    "# Create Faiss Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "262ac9d5-e2e5-4d5b-bd66-686fb99e3bab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index saved to faiis_index_book.index\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "text_ids = [str(i) for i in range(len(text_to_encode))] \n",
    "\n",
    "# Step 2: Create a Faiss index using these embeddings\n",
    "d = text_embeddings.shape[1]  # Dimension of the embeddings\n",
    "index = faiss.IndexFlatL2(d)  # L2 distance metric for the index\n",
    "index.add(text_embeddings)\n",
    "\n",
    "\n",
    "\n",
    "faiss.write_index(index, index_file)\n",
    "print(f\"Index saved to {index_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63685479-045d-4cc8-89db-90c4614a9307",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### we have what we need now let us build the app "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be6d432-c075-405b-8fab-6d2c9b4765c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_keyword = \"example_keyword\"  # Replace with your own keyword\n",
    "\n",
    "# query_embedding = np.random.rand(1, 128).astype('float32')\n",
    "\n",
    "# # Perform the nearest neighbor search\n",
    "# k = 5  # Number of nearest neighbors to retrieve\n",
    "# distances, indices = index.search(query_embedding, k)\n",
    "\n",
    "# # Print the nearest neighbors\n",
    "# print(\"Query Keyword:\", query_keyword)\n",
    "# for i in range(k):\n",
    "#     print(f\"Nearest Neighbor {i + 1} - ID: {ids[indices[0][i]]}, Distance: {distances[0][i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08d1ed43-b88c-4e23-8cc6-9db02ca1fb81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read index\n",
    "\n",
    "import faiss\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2e54434-251c-447c-934c-b6ff13d3b665",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "with open('extracted_data.json','r') as w:\n",
    "    data = json.load(w)\n",
    "    \n",
    "text_to_search = list(data.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bfc4959d-9547-4a63-8f7d-7611a345f41d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "index_file = \"faiis_index_book.index\"\n",
    "book_index = faiss.read_index(index_file)\n",
    "import json \n",
    "with open('extracted_data.json','r') as w:\n",
    "    data = json.load(w)\n",
    "\n",
    "text_to_search = list(data.values())\n",
    "\n",
    "def get_search(query, topK):\n",
    "    query_embedding = embeddings_model.encode([query])\n",
    "    distances, indices = book_index.search(query_embedding, topK)\n",
    "    res = [text_to_search[i] for i in indices[0]]\n",
    "    return \"\\n\".join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69bb1382-d981-41a7-b015-8bea7404310b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Approaching (Almost) Any Machine Learning Problem \\n 184   Model Optimize Range of values Linear Regression  - fit_intercept - normalize   - True/False - True/False Ridge  - alpha - fit_intercept - normalize   - 0.01, 0.1, 1.0, 10, 100 - True/False - True/False k-neighbors  - n_neighbors - p  - 2, 4, 8, 16 …. - 2, 3  SVM  - C - gamma - class_weight   - 0.001,0.01..10..100..1000 - ‘auto’, RS* - ‘balanced’ , None Logistic Regression  - Penalty - C   - l1 or l2 - 0.001, 0.01…..10...100  Lasso  - Alpha - Normalize  - 0.1, 1.0, 10 - True/False  Random Forest  - n_estimators - max_depth - min_samples_split - min_samples_leaf - max features  - 120, 300, 500, 800, 1200 - 5, 8, 15, 25, 30, None - 1, 2, 5, 10, 15, 100 - 1, 2, 5, 10 - log2, sqrt, None  XGBoost  - eta - gamma - max_depth - min_child_weight - subsample - colsample_bytree - lambda - alpha   - 0.01,0.015, 0.025, 0.05, 0.1 - 0.05-0.1,0.3,0.5,0.7,0.9,1.0 - 3, 5, 7, 9, 12, 15, 17, 25 - 1, 3, 5, 7 - 0.6, 0.7, 0.8, 0.9, 1.0 - 0.6, 0.7, 0.8, 0.9, 1.0 - 0.01-0.1, 1.0 , RS* - 0, 0.1, 0.5, 1.0 RS*  \\nApproaching (Almost) Any Machine Learning Problem \\n 110 ═════════════════════════════════════════════════════════════════════════ # ohe_logres.py import pandas as pd  from sklearn import linear_model from sklearn import metrics from sklearn import preprocessing  def run(fold):     # load the full training data with folds     df = pd.read_csv(\"../input/cat_train_folds.csv\")      # all columns are features except id, target and kfold columns     features = [         f for f in df.columns if f not in (\"id\", \"target\", \"kfold\")     ]      # fill all NaN values with NONE     # note that I am converting all columns to \"strings\"     # it doesn’t matter because all are categories     for col in features:         df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")          # get training data using folds     df_train = df[df.kfold != fold].reset_index(drop=True)      # get validation data using folds     df_valid = df[df.kfold == fold].reset_index(drop=True)      # initialize OneHotEncoder from scikit-learn     ohe = preprocessing.OneHotEncoder()      # fit ohe on training + validation features     full_data = pd.concat(         [df_train[features], df_valid[features]],         axis=0     )     ohe.fit(full_data[features])      # transform training data     x_train = ohe.transform(df_train[features])      # transform validation data     x_valid = ohe.transform(df_valid[features])      # initialize Logistic Regression model     model = linear_model.LogisticRegression() \\nApproaching (Almost) Any Machine Learning Problem \\n 66 Now, we come to log loss for multi-label classification. This is quite easy. You can convert the targets to binary format and then use a log loss for each column. In the end, you can take the average of log loss in each column. This is also known as mean column-wise log loss. Of course, there are other ways you can implement this, and you should explore it as you come across it.  We have now reached a stage where we can say that we now know all binary, multi-class and multi-label classification metrics, and now we can move to regression metrics.  The most common metric in regression is error. Error is simple and very easy to understand.  Error = True Value – Predicted Value  Absolute error is just absolute of the above.  Absolute Error = Abs ( True Value – Predicted Value )  Then we have mean absolute error (MAE). It’s just mean of all absolute errors.  ═════════════════════════════════════════════════════════════════════════ import numpy as np   def mean_absolute_error(y_true, y_pred):     \"\"\"     This function calculates mae     :param y_true: list of real numbers, true values     :param y_pred: list of real numbers, predicted values     :return: mean absolute error     \"\"\"     # initialize error at 0     error = 0     # loop over all samples in the true and predicted list     for yt, yp in zip(y_true, y_pred):         # calculate absolute error          # and add to error         error += np.abs(yt - yp)     # return mean error     return error / len(y_true) ═════════════════════════════════════════════════════════════════════════  \\nApproaching (Almost) Any Machine Learning Problem \\n 232         test_df = df[df.kfold == fold_].reset_index(drop=True)          # initialize CountVectorizer with NLTK\\'s word_tokenize         # function as tokenizer         count_vec = CountVectorizer(             tokenizer=word_tokenize,             token_pattern=None         )          # fit count_vec on training data reviews         count_vec.fit(train_df.review)          # transform training and validation data reviews         xtrain = count_vec.transform(train_df.review)         xtest = count_vec.transform(test_df.review)          # initialize logistic regression model         model = linear_model.LogisticRegression()          # fit the model on training data reviews and sentiment         model.fit(xtrain, train_df.sentiment)          # make predictions on test data         # threshold for predictions is 0.5         preds = model.predict(xtest)          # calculate accuracy         accuracy = metrics.accuracy_score(test_df.sentiment, preds)          print(f\"Fold: {fold_}\")         print(f\"Accuracy = {accuracy}\")         print(\"\") ═════════════════════════════════════════════════════════════════════════  This piece of code takes time to run but should give you the following output:  ═════════════════════════════════════════════════════════════════════════ ❯ python ctv_logres.py Fold: 0 Accuracy = 0.8903  Fold: 1 Accuracy = 0.897  Fold: 2 Accuracy = 0.891  \\nApproaching (Almost) Any Machine Learning Problem \\n 69 ═════════════════════════════════════════════════════════════════════════ import numpy as np   def mean_abs_percentage_error(y_true, y_pred):     \"\"\"     This function calculates MAPE     :param y_true: list of real numbers, true values     :param y_pred: list of real numbers, predicted values     :return: mean absolute percentage error     \"\"\"     # initialize error at 0     error = 0     # loop over all samples in true and predicted list     for yt, yp in zip(y_true, y_pred):         # calculate percentage error          # and add to error         error += np.abs(yt - yp) / yt     # return mean percentage error     return error / len(y_true) ═════════════════════════════════════════════════════════════════════════  The best thing about regression is that there are only a few most popular metrics that can be applied to almost every regression problem. And it is much easier to understand when we compare it to classification metrics.   Let’s talk about another regression metric known as R2 (R-squared), also known as the coefficient of determination.   In simple words, R-squared says how good your model fits the data. R-squared closer to 1.0 says that the model fits the data quite well, whereas closer 0 means that model isn’t that good. R-squared can also be negative when the model just makes absurd predictions.   The formula for R-squared is shown in figure 10, but as always a python implementation makes things more clear.     Figure 10: Formula for R-squared \\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_search('Show me a code to build logisitic regression ?', 5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d591c547-aecd-43a3-b99f-87d306be8612",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
